{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c32dccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import time, copy, math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bbad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP1: Set up directories\n",
    "training_dir = Path(\"C:/Users/tomla/Documents/Projects/brain_tumor_classifier/data/training/\")\n",
    "testing_dir = Path(\"C:/Users/tomla/Documents/Projects/brain_tumor_classifier/data/testing/\")\n",
    "OUTPUT_MODELS = Path(\"C:/Users/tomla/Documents/Projects/brain_tumor_classifier/models/\")\n",
    "OUTPUT_MODELS.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42561c6",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e56bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Set up transforms for image Normalization and Augmentation\n",
    "\n",
    "# Image Normalization paramters for ResNet18\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.RandomRotation(15), \n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce5e424c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Create Dataloaders\n",
    "\n",
    "# Load full training set\n",
    "full_train = ImageFolder(training_dir, transform=data_transforms[\"train\"]) # load full training dataset and assigns label to each image based on folder class\n",
    "y = np.array([label for _, label in full_train.samples]) # extract labels\n",
    "\n",
    "# Create stratified split (80% train / 20% val)\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(ss.split(np.zeros(len(y)), y)) # create indices for train/val split (requires X, y so zero array is used as X)\n",
    "\n",
    "# training set\n",
    "train_data = Subset(full_train, train_idx)\n",
    "\n",
    "# validation set\n",
    "val_train = ImageFolder(training_dir, transform=data_transforms[\"val\"]) # load full training dataset without agumentations\n",
    "val_data = Subset(val_train, val_idx)\n",
    "\n",
    "# final test set\n",
    "test_data = ImageFolder(testing_dir, transform=data_transforms[\"test\"])\n",
    "\n",
    "# Loaders\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "class_names = full_train.classes  # ordered by subfolder name\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "890c698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\tomla/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 46.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Load pretrained Model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "model = resnet18(weights=weights)\n",
    "\n",
    "# replace final layer for 4 classes\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ae573e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:30: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/15] 18.3s  TrainLoss=0.4651  Val: Acc=0.908  P=0.913  R=0.903  F1=0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/15] 17.6s  TrainLoss=0.1610  Val: Acc=0.936  P=0.940  R=0.931  F1=0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/15] 17.4s  TrainLoss=0.1005  Val: Acc=0.949  P=0.953  R=0.941  F1=0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/15] 17.8s  TrainLoss=0.0668  Val: Acc=0.943  P=0.951  R=0.940  F1=0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/15] 17.8s  TrainLoss=0.0531  Val: Acc=0.946  P=0.944  R=0.941  F1=0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/15] 18.0s  TrainLoss=0.0272  Val: Acc=0.962  P=0.959  R=0.960  F1=0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/15] 17.8s  TrainLoss=0.0170  Val: Acc=0.963  P=0.965  R=0.962  F1=0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/15] 17.6s  TrainLoss=0.0169  Val: Acc=0.967  P=0.966  R=0.963  F1=0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/15] 17.7s  TrainLoss=0.0114  Val: Acc=0.969  P=0.968  R=0.964  F1=0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/15] 17.7s  TrainLoss=0.0136  Val: Acc=0.960  P=0.960  R=0.954  F1=0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/15] 17.4s  TrainLoss=0.0121  Val: Acc=0.960  P=0.962  R=0.952  F1=0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/15] 17.4s  TrainLoss=0.0148  Val: Acc=0.967  P=0.968  R=0.963  F1=0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/15] 17.4s  TrainLoss=0.0093  Val: Acc=0.970  P=0.971  R=0.966  F1=0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/15] 17.3s  TrainLoss=0.0075  Val: Acc=0.962  P=0.961  R=0.952  F1=0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomla\\AppData\\Local\\Temp\\ipykernel_54716\\3327404457.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/15] 17.6s  TrainLoss=0.0076  Val: Acc=0.965  P=0.966  R=0.958  F1=0.962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 5: Run Train/validate loop with metrics\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer / scheduler\n",
    "import torch.optim as optim\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # gentle decay\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(yb.cpu())\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    return acc, prec, rec, f1, y_true, y_pred\n",
    "\n",
    "EPOCHS = 15\n",
    "best_wts = copy.deepcopy(model.state_dict())\n",
    "best_f1 = -math.inf\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    # ---- train ----\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # ---- validate ----\n",
    "    val_acc, val_prec, val_rec, val_f1, y_true, y_pred = evaluate(model, val_loader, device)\n",
    "\n",
    "    # track best\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_wts, OUTPUT_MODELS / f\"resnet18_best_valF1_{best_f1:.3f}.pth\")\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[{epoch:02d}/{EPOCHS}] {dt:.1f}s  TrainLoss={train_loss:.4f}  \"\n",
    "          f\"Val: Acc={val_acc:.3f}  P={val_prec:.3f}  R={val_rec:.3f}  F1={val_f1:.3f}\")\n",
    "\n",
    "# load best weights\n",
    "model.load_state_dict(best_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43520379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST — Acc=0.774  P=0.839  R=0.761  F1=0.752\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    glioma_tumor       0.92      0.35      0.51       100\n",
      "meningioma_tumor       0.69      0.99      0.81       115\n",
      "        no_tumor       0.74      0.97      0.84       105\n",
      " pituitary_tumor       1.00      0.73      0.84        74\n",
      "\n",
      "        accuracy                           0.77       394\n",
      "       macro avg       0.84      0.76      0.75       394\n",
      "    weighted avg       0.82      0.77      0.75       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Final model evaluation on test set\n",
    "test_acc, test_prec, test_rec, test_f1, y_true, y_pred = evaluate(model, test_loader, device)\n",
    "print(f\"TEST — Acc={test_acc:.3f}  P={test_prec:.3f}  R={test_rec:.3f}  F1={test_f1:.3f}\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcdb24d",
   "metadata": {},
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a287d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN mapping: {'glioma_tumor': 0, 'meningioma_tumor': 1, 'no_tumor': 2, 'pituitary_tumor': 3}\n",
      "TEST  mapping: {'glioma_tumor': 0, 'meningioma_tumor': 1, 'no_tumor': 2, 'pituitary_tumor': 3}\n",
      "Index remap: {0: 0, 1: 1, 2: 2, 3: 3}\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Check index remap\n",
    "print(\"TRAIN mapping:\", full_train.class_to_idx)\n",
    "print(\"TEST  mapping:\", test_data.class_to_idx)\n",
    "\n",
    "# Must match by class name → same index\n",
    "assert set(full_train.classes) == set(test_data.classes)\n",
    "\n",
    "# If order differs, build an index remap for evaluation\n",
    "train_map = full_train.class_to_idx           # {'glioma':0, 'meningioma':1, ...}\n",
    "test_map  = test_data.class_to_idx              # may be different order\n",
    "\n",
    "idx_remap = {test_idx: train_map[name] for name, test_idx in test_map.items()}\n",
    "print(\"Index remap:\", idx_remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6a6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
